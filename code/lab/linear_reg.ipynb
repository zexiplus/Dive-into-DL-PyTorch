{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd06a7cafeaeb3fd68df71f631e022add281d537fd7827e106ecab671299a698970",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1.1942, 1.3375], requires_grad=True)\ntensor([ 3.0938, -4.4622], requires_grad=True) tensor(5.4670, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 线性回归手动实现\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = torch.tensor([3.1, -4.5])\n",
    "true_b = torch.tensor(5.5)\n",
    "\n",
    "features = torch.randn(num_examples, num_inputs)\n",
    "labels = features.mm(true_w.unsqueeze(-1)) + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, (num_examples, 1)))\n",
    "\n",
    "lr = 0.01\n",
    "epoch = 5\n",
    "batch_size = 10\n",
    "\n",
    "# 随机初始化参数\n",
    "w = torch.randn(num_inputs, requires_grad=True)\n",
    "b = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "print(w)\n",
    "\n",
    "# 定义数据迭代器\n",
    "\n",
    "def data_iter(num_examples, batch_size, features, labels):\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.tensor(indices[i: min(i+batch_size, num_examples)])\n",
    "        yield features.index_select(0, j), labels.index_select(0, j)\n",
    "    \n",
    "\n",
    "# 定义模型\n",
    "\n",
    "def lin_reg(w, b, feature):\n",
    "    return feature.mm(w.view(feature.shape[1], -1)) + b\n",
    "\n",
    "\n",
    "# 定义损失函数\n",
    "def loss(y, y_pred):\n",
    "    return (y_pred - y).pow(2) / 2\n",
    "    \n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "\n",
    "def sgd(params, lr):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad.data\n",
    "\n",
    "# 训练\n",
    "\n",
    "for e in range(epoch):\n",
    "    for X, y in data_iter(num_examples, batch_size, features, labels):\n",
    "        y_pred = lin_reg(w, b, X)\n",
    "        l = loss(y, y_pred).sum() / batch_size\n",
    "        l.backward()\n",
    "        sgd([w, b], lr)\n",
    "\n",
    "        # 每个 batch_size 迭代后梯度清零\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "print(w, b)\n",
    "        \n",
    "\n",
    "\n",
    "# plt.scatter(features[:, 0], labels, 1)\n",
    "# plt.scatter(features[:, 1], labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性回归 pytorch 实现\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "num_examples = 1000\n",
    "num_inputs = 2\n",
    "\n",
    "true_w = torch.tensor([3.3, 5.1])\n",
    "true_b = torch.tensor(8.9)\n",
    "\n",
    "features = torch.randn(num_examples, num_inputs)\n",
    "labels = features.mm(true_w.view(2,1)) + true_b\n",
    "noise = torch.tensor(np.random.normal(0, 0.01, size=(num_examples, 1)))\n",
    "labels += noise\n",
    "\n",
    "\n",
    "# pyplot.scatter(features[:, 0], labels, 1)\n",
    "# pyplot.scatter(features[:, 1], labels, 1)\n",
    "\n",
    "batch_size = 12\n",
    "lr = 0.02\n",
    "epoch = 5\n",
    "\n",
    "# 数据读取对象\n",
    "data_sets = data.TensorDataset(features, labels)\n",
    "data_iter = data.DataLoader(dataset=data_sets, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for X, y in data_iter(features, labels, num_examples, batch_size):\n",
    "#     print(X, y)\n",
    "#     break\n",
    "\n",
    "# 定义网络        \n",
    "net = nn.Sequential(nn.Linear(2,1))\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr)\n",
    "\n",
    "# 定义损失函数\n",
    "def loss(y, y_pred, batch_size):\n",
    "    return (y - y_pred).pow(2).sum() / batch_size\n",
    "\n",
    "# 训练\n",
    "\n",
    "for e in range(epoch):\n",
    "    for X, y in data_iter:\n",
    "        y_pred = net(X)\n",
    "        l = loss(y, y_pred, batch_size)\n",
    "        # 反向传播计算梯度\n",
    "        l.backward()\n",
    "        # 正向更新参数\n",
    "        optimizer.step()\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "print(net[0].weight)\n",
    "print(net[0].bias)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}