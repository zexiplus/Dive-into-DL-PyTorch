{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "6a7cafeaeb3fd68df71f631e022add281d537fd7827e106ecab671299a698970"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 数字识别线性神经网络实现"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy tensor(0.8662)\n",
      "accuracy tensor(0.9007)\n",
      "accuracy tensor(0.9077)\n",
      "accuracy tensor(0.9114)\n",
      "accuracy tensor(0.9151)\n",
      "(28, 28)\n",
      "result is  3\n",
      "shape torch.Size([1, 28, 28])\n",
      "test[0] label is  7\n",
      "predict test[0] is 7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "\n",
    "train_data = torchvision.datasets.QMNIST('~/Datasets/QMNIST', train=True, transform=torchvision.transforms.ToTensor())\n",
    "test_data = torchvision.datasets.QMNIST('~/Datasets/QMNIST', train=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "lr = 0.1\n",
    "epoch = 5\n",
    "batch_size=100\n",
    "\n",
    "data_iter = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# for feature, label in data_iter:\n",
    "#     print(feature.shape)\n",
    "#     print(label)\n",
    "#     break\n",
    "\n",
    "# 返回 shape: 100(batch_size) x 784 的 tensor\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        # 原 shape [batch_size, 1, 28, 28] 返回 [batch_size, 784]\n",
    "        return x.view(x.shape[0], -1)\n",
    "    \n",
    "\n",
    "net = nn.Sequential(OrderedDict([('Flatten', FlattenLayer()), ('Linear', nn.Linear(784, 10))]))\n",
    "\n",
    "optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "for e in range(epoch):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, y in data_iter:\n",
    "        y_pred = net(X)\n",
    "        l = loss(y_pred, y).sum()\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        correct += (y_pred.argmax(dim=1) == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "    print('accuracy', correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "img = cv2.imread('./data/3.png', 0)\n",
    "\n",
    "unloader = torchvision.transforms.ToPILImage()\n",
    "\n",
    "r_img = cv2.resize(img, (28, 28))\n",
    "\n",
    "print(r_img.shape) # (28, 28)\n",
    "\n",
    "t_img = torchvision.transforms.functional.to_tensor(r_img)\n",
    "\n",
    "\n",
    "\n",
    "pyplot.imshow(unloader(t_img), cmap=\"gray\")\n",
    "\n",
    "\n",
    "print('result is ', net(t_img.unsqueeze(0)).argmax().item())\n",
    "\n",
    "predict_label = test_data[0][1]\n",
    "predict_data = test_data[0][0]\n",
    "\n",
    "print('shape', predict_data.shape) # torch.Size([1, 28, 28])\n",
    "\n",
    "\n",
    "pyplot.imshow(predict_data.view(28, 28), cmap=\"gray\")\n",
    "\n",
    "print('test[0] label is ', predict_label)\n",
    "print('predict test[0] is', net(predict_data).argmax().item())"
   ]
  },
  {
   "source": [
    "## 数字识别多层神经网络实现"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "train_data = torchvision.datasets.QMNIST('~/Datasets/QMNIST', train=True, transform=torchvision.transforms.ToTensor())\n",
    "test_data = torchvision.datasets.QMNIST('~/Datasets/QMNIST', train=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "lr = 0.1\n",
    "epoch = 10\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_iter = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# for feature, label in train_iter:\n",
    "#     print(feature.shape)\n",
    "#     print(label)\n",
    "#     break\n",
    "\n",
    "# 返回 shape: 100(batch_size) x 784 的 tensor\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        # 原 shape [batch_size, 1, 28, 28] 返回 [batch_size, 784]\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "num_outputs = 10\n",
    "    \n",
    "\n",
    "net = nn.Sequential(\n",
    "    FlattenLayer(),\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10))\n",
    "\n",
    "optim = torch.optim.SGD(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "for e in range(epoch):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, y in train_iter:\n",
    "        y_pred = net(X)\n",
    "        l = loss(y_pred, y).sum()\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        correct += (y_pred.argmax(dim=1) == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "    test_acc = d2l.evaluate_accuracy(test_iter, net)\n",
    "    print('[Epoch]', e)\n",
    "    print('[Train accuracy]', (correct / total).item())\n",
    "    print('[test accuracy]', test_acc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/3.png', 0)\n",
    "\n",
    "unloader = torchvision.transforms.ToPILImage()\n",
    "\n",
    "r_img = cv2.resize(img, (28, 28))\n",
    "\n",
    "print(r_img.shape) # (28, 28)\n",
    "\n",
    "t_img = torchvision.transforms.functional.to_tensor(r_img)\n",
    "\n",
    "\n",
    "\n",
    "pyplot.imshow(unloader(t_img), cmap=\"gray\")\n",
    "\n",
    "\n",
    "print('result is ', net(t_img.unsqueeze(0)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.random_integers(0, 9999)\n",
    "predict_label = test_data[index][1]\n",
    "predict_data = test_data[index][0]\n",
    "\n",
    "\n",
    "print('shape', predict_data.shape) # torch.Size([1, 28, 28])\n",
    "\n",
    "\n",
    "pyplot.imshow(predict_data.view(28, 28), cmap=\"gray\")\n",
    "\n",
    "print('[num label] ', predict_label)\n",
    "print('[predict result]', net(predict_data).argmax().item())"
   ]
  },
  {
   "source": [
    "## 数字识别卷积实现"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "trans = torchvision.transforms.Compose([torchvision.transforms.Resize(224), torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_data = torchvision.datasets.QMNIST('~/Datasets/QMNIST', train=True, download=True, transform=trans)\n",
    "test_data = torchvision.datasets.QMNIST('~/Datasets/QMNIST', train=False, download=True, transform=trans)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lr = 0.01\n",
    "epoch = 10\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_iter = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# for feature, label in train_iter:\n",
    "#     print(feature.shape)\n",
    "#     print(label)\n",
    "#     break\n",
    "\n",
    "# 返回 shape: 100(batch_size) x 784 的 tensor\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        # 原 shape [batch_size, 1, 28, 28] 返回 [batch_size, 784]\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "num_outputs = 10\n",
    "\n",
    "\n",
    "class Reshape(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, 1, 28, 28)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
    "    nn.Linear(6400, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 10)).to(device)\n",
    "\n",
    "optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 查看每层处理结果形状\n",
    "# X = torch.randn(1, 1, 224, 224)\n",
    "# for layer in net:\n",
    "#     X = layer(X)\n",
    "#     print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "\n",
    "for e in range(epoch):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, y in train_iter:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        y_pred = net(X)\n",
    "        l = loss(y_pred, y).sum()\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        correct += (y_pred.argmax(dim=1) == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "    test_acc = d2l.evaluate_accuracy(test_iter, net)\n",
    "    print('[Epoch]', e)\n",
    "    print('[Train accuracy]', (correct / total).item())\n",
    "    print('[test accuracy]', test_acc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/9.png', 0)\n",
    "\n",
    "unloader = torchvision.transforms.ToPILImage()\n",
    "\n",
    "# 把图片大小缩放为合适尺寸\n",
    "r_img = cv2.resize(img, (224, 224))\n",
    "\n",
    "print(r_img.shape) # (224, 224)\n",
    "\n",
    "t_img = torchvision.transforms.functional.to_tensor(r_img).to(device)\n",
    "\n",
    "\n",
    "\n",
    "pyplot.imshow(unloader(t_img), cmap=\"gray\")\n",
    "\n",
    "\n",
    "print('result is ', net(t_img.unsqueeze(0)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.random_integers(0, 9999)\n",
    "predict_label = test_data[index][1]\n",
    "predict_data = test_data[index][0]\n",
    "\n",
    "\n",
    "print('shape', predict_data.shape) # torch.Size([1, 28, 28])\n",
    "\n",
    "\n",
    "pyplot.imshow(predict_data.view(28, 28), cmap=\"gray\")\n",
    "\n",
    "print('[num label] ', predict_label)\n",
    "print('[predict result]', net(predict_data).argmax().item())"
   ]
  }
 ]
}