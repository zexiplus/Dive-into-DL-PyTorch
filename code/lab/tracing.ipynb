{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "6a7cafeaeb3fd68df71f631e022add281d537fd7827e106ecab671299a698970"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MyCell(\n  original_name=MyCell\n  (linear): Linear(original_name=Linear)\n)\nMyCell(\n  (linear): Linear(in_features=4, out_features=4, bias=True)\n)\n(tensor([[-0.0088,  0.7755,  0.6305,  0.5801],\n        [ 0.1678,  0.6604,  0.7539,  0.1250],\n        [ 0.1615,  0.8975,  0.7795,  0.1506]], grad_fn=<TanhBackward>), tensor([[-0.0088,  0.7755,  0.6305,  0.5801],\n        [ 0.1678,  0.6604,  0.7539,  0.1250],\n        [ 0.1615,  0.8975,  0.7795,  0.1506]], grad_fn=<TanhBackward>))\ngraph(%self.1 : __torch__.___torch_mangle_19.MyCell,\n      %input : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n  %21 : __torch__.torch.nn.modules.linear.___torch_mangle_18.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n  %23 : Tensor = prim::CallMethod[name=\"forward\"](%21, %input)\n  %14 : int = prim::Constant[value=1]() # <ipython-input-8-634fc8f2c412>:7:0\n  %15 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%23, %h, %14) # <ipython-input-8-634fc8f2c412>:7:0\n  %16 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%15) # <ipython-input-8-634fc8f2c412>:7:0\n  %17 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%16, %16)\n  return (%17)\n\ndef forward(self,\n    input: Tensor,\n    h: Tensor) -> Tuple[Tensor, Tensor]:\n  _0 = torch.add((self.linear).forward(input, ), h, alpha=1)\n  _1 = torch.tanh(_0)\n  return (_1, _1)\n\n"
     ]
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "\n",
    "print(traced_cell)\n",
    "print(my_cell)\n",
    "print(traced_cell(x, h))\n",
    "# \n",
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "def forward(self,\n    input: Tensor,\n    h: Tensor) -> Tuple[Tensor, Tensor]:\n  _0 = torch.add((self.linear).forward(input, ), h, alpha=1)\n  _1 = torch.tanh(_0)\n  return (_1, _1)\n\n"
     ]
    }
   ],
   "source": [
    "# python interpretation\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}