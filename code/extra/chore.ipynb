{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd06a7cafeaeb3fd68df71f631e022add281d537fd7827e106ecab671299a698970",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def te_none(a):\n",
    "    print(a is None)\n",
    "\n",
    "te_none(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# item\n",
    "a = torch.tensor([3])\n",
    "print(a.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "# 正确率\n",
    "y_hat = torch.tensor([[0.5, 0.2, 0.3], [0.1, 0.2, 0.7]])\n",
    "y = torch.tensor([0, 2])\n",
    "print('accu', (y_hat.argmax(dim=1) == y).sum().item() / y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[0.6961, 0.0919, 0.9415, 0.8009],\n         [0.5881, 0.0337, 0.0220, 0.5437],\n         [0.8957, 0.8959, 0.8249, 0.2478]],\n\n        [[0.4575, 0.0767, 0.0032, 0.4745],\n         [0.8499, 0.3540, 0.8056, 0.4436],\n         [0.9746, 0.6835, 0.5805, 0.0035]]])\ntorch.Size([2, 3, 4])\n2\ntensor([[0.6961, 0.0919, 0.9415, 0.8009, 0.5881, 0.0337, 0.0220, 0.5437, 0.8957,\n         0.8959, 0.8249, 0.2478],\n        [0.4575, 0.0767, 0.0032, 0.4745, 0.8499, 0.3540, 0.8056, 0.4436, 0.9746,\n         0.6835, 0.5805, 0.0035]])\ntorch.Size([2, 12])\ntorch.Size([4])\ntensor([ True, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "a = torch.rand((2,3,4))\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.shape[0])\n",
    "\n",
    "b = a.view(a.shape[0], -1)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "\n",
    "c = torch.tensor([3,4,5,6])\n",
    "d = torch.tensor([3,2,5,6])\n",
    "print(c.shape)\n",
    "print(c == d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a.argmax(dim=0),  tensor([0, 1, 1])\na.argmax(dim=1) tensor([0, 2])\n"
     ]
    }
   ],
   "source": [
    "# argmax\n",
    "a = torch.tensor([\n",
    "    [9,2,1], \n",
    "    [4,5,8]])\n",
    "\n",
    "print('a.argmax(dim=0), ', a.argmax(dim=0))\n",
    "\n",
    "print('a.argmax(dim=1)', a.argmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear(in_features=3, out_features=4, bias=True)\n",
      "Linear(in_features=4, out_features=5, bias=True) \n",
      "\n",
      "tensor([[ 93.0093, 103.5457,  98.6235,  94.2734, 113.2469],\n",
      "        [ 80.6863,  91.8545,  99.9626, 102.9370, 108.2044],\n",
      "        [111.8902,  94.7749,  71.7258,  94.8969,  79.8990]])\n",
      "parameters ----\n",
      "Parameter containing:\n",
      "tensor([[-0.3172,  0.0427,  0.3532],\n",
      "        [-0.5551, -0.0534,  0.0465],\n",
      "        [-0.3285,  0.4402, -0.0092],\n",
      "        [-0.0052,  0.0458,  0.2975]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1107,  0.4387,  0.2176, -0.4730], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0706,  0.0585,  0.2501,  0.3465],\n",
      "        [ 0.2940, -0.2512,  0.3615,  0.4334],\n",
      "        [-0.2040,  0.0042, -0.1167,  0.1213],\n",
      "        [ 0.1963, -0.3190, -0.1602,  0.3305],\n",
      "        [-0.0997, -0.2576, -0.2656,  0.0197]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2416,  0.4389,  0.2887,  0.4688, -0.4241], requires_grad=True)\n",
      "ipykernel_launcher:9: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
     ]
    }
   ],
   "source": [
    "# net.parametes()\n",
    "import torch\n",
    "l1 = torch.nn.Linear(3,4, bias=True)\n",
    "l2 = torch.nn.Linear(4,5, bias=True)\n",
    "net = torch.nn.Sequential(l1, l2)\n",
    "print(l1)\n",
    "print(l2, '\\n')\n",
    "\n",
    "w = torch.empty(3, 5)\n",
    "torch.nn.init.normal(w, mean=100, std=10)\n",
    "print(w)\n",
    "\n",
    "print('parameters ----')\n",
    "\n",
    "# 因为有 weight, bias 所以有 4 个参数层\n",
    "for p in net.parameters():\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-3.1416, -3.1384, -3.1353,  ...,  3.1353,  3.1384,  3.1416])\n"
     ]
    }
   ],
   "source": [
    "# torch.linspace\n",
    "import math\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True \n -----\nFalse\nNone\nFalse\n"
     ]
    }
   ],
   "source": [
    "# with torch.no_grad() 子树不记录梯度\n",
    "x = torch.randn(10, 5, requires_grad = True)\n",
    "y = torch.randn(10, 5, requires_grad = True)\n",
    "z = torch.randn(10, 5, requires_grad = True)\n",
    "\n",
    "n = x + y + z\n",
    "print(n.requires_grad, '\\n -----')\n",
    "\n",
    "with torch.no_grad():\n",
    "    w = x + y + z\n",
    "    print(w.requires_grad)\n",
    "    print(w.grad_fn)\n",
    "print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(135)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "# pow\n",
    "a = torch.tensor([[1,2,3], [2,3,4]])\n",
    "print(a.pow(3).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\n---\nTrue\nFalse\n---\nTrue\nFalse\nFalse\n"
     ]
    }
   ],
   "source": [
    "# is vs ==\n",
    "a = 1\n",
    "b = 1\n",
    "print(a==b)\n",
    "print(a is b)\n",
    "print('---')\n",
    "\n",
    "\n",
    "a = 2.0\n",
    "b = 2.0\n",
    "print(a == b)\n",
    "print(a is b)\n",
    "print('---')\n",
    "\n",
    "a = {'value': 1}\n",
    "b = {'value': 1}\n",
    "print(a == b)\n",
    "print(a is b)\n",
    "print(id(a) == id(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5])\ntorch.Size([5, 1])\ntensor([[  1,   1,   1],\n        [  2,   4,   8],\n        [  3,   9,  27],\n        [  4,  16,  64],\n        [  5,  25, 125]])\n"
     ]
    }
   ],
   "source": [
    "# unsequeeze 膨胀\n",
    "\n",
    "a = torch.tensor([1,2,3,4,5])\n",
    "b = torch.tensor([1,2,3])\n",
    "# print(a.unsqueeze(0))\n",
    "# print(a.unsqueeze(1))\n",
    "# print(a.shape)\n",
    "\n",
    "\n",
    "x = torch.tensor([1,2,3,4,5])\n",
    "b = torch.tensor([1,2,3])\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "sx = x.unsqueeze(1)\n",
    "print(sx.shape)\n",
    "\n",
    "xx = sx.pow(b)\n",
    "print(xx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([0.4926, 0.3428], requires_grad=True) Parameter containing:\ntensor([[ 0.2038, -0.3172, -0.0947],\n        [-0.1097, -0.0581,  0.5024]], requires_grad=True)\noutput tensor([[-0.2220,  1.6240],\n        [-0.1690,  0.0059],\n        [-0.7285,  2.5707],\n        [ 0.7911, -0.2694],\n        [ 2.2939, -2.2102]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear\n",
    "\n",
    "\n",
    "m = torch.nn.Linear(3, 2, bias=True) # 创建 Linear 层时会随机初始化 w, b\n",
    "\n",
    "# 5 x 3 矩阵\n",
    "input = torch.tensor([\n",
    "        [1,  2,  3],\n",
    "        [5, 5,  1],\n",
    "        [1,  3, 5],\n",
    "        [ 1,  0, -1],\n",
    "        [ 9, 1, -3]], dtype=torch.float32)\n",
    "\n",
    "print(m.bias, m.weight)\n",
    "\n",
    "print('output', m(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([3, 2, 3, 4, 5, 3])\ntensor([[3, 2, 3, 4, 5, 3]])\ntensor([[[3, 2, 3],\n         [4, 5, 3]]])\n"
     ]
    }
   ],
   "source": [
    "# nn.Flatten\n",
    "\n",
    "m0 = torch.nn.Flatten(0)\n",
    "m1 = torch.nn.Flatten(1)\n",
    "m2 = torch.nn.Flatten(2)\n",
    "m3 = torch.nn.Flatten(3)\n",
    "\n",
    "t = torch.tensor([[[3,2,3], [4,5,3]]])\n",
    "\n",
    "\n",
    "print(m0(t))\n",
    "print(m1(t))\n",
    "print(m2(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}