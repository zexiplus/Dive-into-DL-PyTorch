{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.10 多层感知机的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10.1 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs = 784 \n",
    "num_outputs = 10\n",
    "num_hiddens = 256\n",
    "    \n",
    "net = nn.Sequential(\n",
    "        nn.Flatten(), # 保留第 0 维， 其他维度碾平\n",
    "        nn.Linear(num_inputs, num_hiddens), # shape: 784 x 256\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_hiddens, num_outputs), # shape: 256 x 10\n",
    "        )\n",
    "\n",
    "# 实际上 pytorch 会自动初始化参数, 以下两行运行不影响实际结果\n",
    "# for params in net.parameters():\n",
    "#     init.normal_(params, mean=0, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[-0.0171, -0.0056,  0.0147,  ..., -0.0205, -0.0121,  0.0243],\n        [ 0.0019,  0.0246, -0.0232,  ...,  0.0292,  0.0012,  0.0153],\n        [-0.0166,  0.0092,  0.0111,  ..., -0.0136, -0.0012, -0.0028],\n        ...,\n        [-0.0285,  0.0353, -0.0109,  ...,  0.0235, -0.0082, -0.0203],\n        [-0.0055,  0.0169,  0.0258,  ..., -0.0211,  0.0335,  0.0270],\n        [ 0.0124,  0.0286, -0.0092,  ..., -0.0048, -0.0231, -0.0309]],\n       requires_grad=True)\nParameter containing:\ntensor([-0.0254, -0.0029, -0.0108, -0.0327,  0.0345, -0.0022,  0.0125,  0.0129,\n         0.0005, -0.0087, -0.0033,  0.0240,  0.0327,  0.0165, -0.0263,  0.0247,\n         0.0312, -0.0106, -0.0114,  0.0158,  0.0174, -0.0315,  0.0247, -0.0040,\n         0.0280, -0.0125,  0.0038, -0.0156,  0.0322,  0.0352,  0.0176,  0.0111,\n        -0.0027, -0.0279,  0.0046,  0.0242, -0.0086,  0.0265, -0.0307, -0.0008,\n        -0.0213,  0.0221,  0.0122, -0.0187, -0.0109, -0.0272, -0.0044, -0.0286,\n        -0.0238,  0.0151,  0.0135, -0.0093, -0.0236, -0.0284, -0.0085, -0.0146,\n        -0.0277,  0.0194, -0.0014,  0.0113,  0.0344,  0.0224, -0.0116,  0.0125,\n        -0.0301, -0.0297, -0.0265, -0.0112,  0.0207, -0.0305, -0.0343, -0.0306,\n        -0.0074,  0.0198,  0.0326,  0.0261,  0.0169, -0.0165,  0.0160,  0.0271,\n        -0.0304, -0.0161, -0.0030, -0.0327,  0.0356,  0.0135, -0.0177, -0.0093,\n         0.0076, -0.0134, -0.0335,  0.0167, -0.0027, -0.0303,  0.0090,  0.0258,\n        -0.0169,  0.0037,  0.0101, -0.0059,  0.0079, -0.0302,  0.0128,  0.0011,\n        -0.0140, -0.0294, -0.0050,  0.0245, -0.0239,  0.0322,  0.0299, -0.0346,\n        -0.0343, -0.0259, -0.0262, -0.0102, -0.0057,  0.0215, -0.0244,  0.0291,\n         0.0149, -0.0187, -0.0028,  0.0065,  0.0268,  0.0341, -0.0144,  0.0049,\n         0.0077, -0.0225, -0.0293,  0.0042,  0.0225, -0.0131,  0.0357,  0.0342,\n        -0.0193, -0.0158,  0.0093,  0.0157, -0.0162, -0.0001, -0.0068, -0.0184,\n        -0.0190, -0.0319, -0.0292,  0.0178, -0.0197,  0.0096, -0.0246,  0.0117,\n         0.0011, -0.0211, -0.0354, -0.0317, -0.0312,  0.0240, -0.0053, -0.0047,\n        -0.0032, -0.0011,  0.0297,  0.0068, -0.0308,  0.0316,  0.0145,  0.0034,\n         0.0275, -0.0142,  0.0277, -0.0322, -0.0051, -0.0027, -0.0343, -0.0214,\n        -0.0163,  0.0284,  0.0041,  0.0313,  0.0113,  0.0347, -0.0113,  0.0236,\n        -0.0301,  0.0108, -0.0341,  0.0042, -0.0210,  0.0227, -0.0111, -0.0273,\n        -0.0152,  0.0002,  0.0334,  0.0223, -0.0087, -0.0100, -0.0101,  0.0224,\n         0.0307, -0.0022, -0.0083, -0.0116, -0.0311,  0.0237, -0.0281, -0.0074,\n         0.0214,  0.0090, -0.0310,  0.0274,  0.0053,  0.0180,  0.0187,  0.0300,\n        -0.0344, -0.0296, -0.0316, -0.0084,  0.0143,  0.0096,  0.0315, -0.0062,\n        -0.0100,  0.0169, -0.0032,  0.0214,  0.0110,  0.0314,  0.0344,  0.0273,\n        -0.0277, -0.0070, -0.0068, -0.0177, -0.0307, -0.0351,  0.0162,  0.0129,\n        -0.0268, -0.0228,  0.0024,  0.0150, -0.0046, -0.0188,  0.0097,  0.0026,\n        -0.0189,  0.0290,  0.0134,  0.0154,  0.0087, -0.0131, -0.0264, -0.0189],\n       requires_grad=True)\nParameter containing:\ntensor([[-0.0418, -0.0189, -0.0003,  ..., -0.0054,  0.0613,  0.0336],\n        [-0.0308,  0.0211, -0.0145,  ...,  0.0161,  0.0577,  0.0335],\n        [ 0.0499,  0.0558,  0.0195,  ...,  0.0217, -0.0568, -0.0089],\n        ...,\n        [-0.0601,  0.0054, -0.0086,  ...,  0.0017,  0.0519, -0.0247],\n        [ 0.0188,  0.0199,  0.0147,  ...,  0.0442, -0.0423, -0.0118],\n        [ 0.0621,  0.0623,  0.0351,  ...,  0.0414,  0.0130,  0.0330]],\n       requires_grad=True)\nParameter containing:\ntensor([ 0.0144,  0.0512, -0.0369,  0.0499,  0.0575, -0.0478,  0.0417, -0.0455,\n        -0.0151,  0.0103], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10.2 读取数据并训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(mnist_train) 60000\n",
      "len(mnist_test) 10000\n",
      "235\n",
      "40\n",
      "epoch 1, loss 0.0069, train acc 0.556, test acc 0.650\n",
      "epoch 2, loss 0.0042, train acc 0.671, test acc 0.672\n",
      "epoch 3, loss 0.0034, train acc 0.705, test acc 0.708\n",
      "epoch 4, loss 0.0030, train acc 0.736, test acc 0.737\n",
      "epoch 5, loss 0.0028, train acc 0.759, test acc 0.758\n",
      "epoch 6, loss 0.0026, train acc 0.775, test acc 0.773\n",
      "epoch 7, loss 0.0025, train acc 0.787, test acc 0.779\n",
      "epoch 8, loss 0.0024, train acc 0.798, test acc 0.786\n",
      "epoch 9, loss 0.0023, train acc 0.804, test acc 0.794\n",
      "epoch 10, loss 0.0022, train acc 0.810, test acc 0.799\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "# 迭代次数 = 样本总数 / batch_size\n",
    "print(len(train_iter))\n",
    "print(len(test_iter))\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 10\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3613jvsc74a57bd06a7cafeaeb3fd68df71f631e022add281d537fd7827e106ecab671299a698970",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}